<h1 align="center">
  Apache Airflow Provider for RabbitMQ
</h1>
<h3 align="center">
  Хуки, операторы, сенсоры и отложенные триггеры для интеграции RabbitMQ в Apache Airflow.
</h3>

<p align="center">
  <a href="#установка">Установка</a> &bull;
  <a href="#настройка-подключения">Подключение</a> &bull;
  <a href="#компоненты">Компоненты</a> &bull;
  <a href="#примеры-dag">Примеры</a> &bull;
  <a href="#участие-в-разработке">Участие</a>
</p>

---

> **Раскрытие информации об ИИ:** Этот провайдер разработан при участии **Claude Code** (Anthropic, модель **Claude Opus 4.6**). Код, тесты и документация написаны совместно разработчиком и LLM. Оценивайте качество кода по его содержанию и принимайте осознанное решение о том, использовать ли его в своих проектах.

---

## Обзор

`apache-airflow-provider-rmq` — это провайдер для Apache Airflow, обеспечивающий взаимодействие с RabbitMQ. Возможности:

- Публикация сообщений в обменники (exchanges) и очереди
- Потребление сообщений с фильтрацией по заголовкам и пользовательским функциям
- Ожидание конкретных сообщений с помощью сенсоров (классический poke-режим и отложенный/deferrable режим)
- Полное управление очередями и обменниками (создание, удаление, очистка, привязка, отвязка)
- SSL/TLS подключения
- Помощник для настройки Dead Letter Queue (DLQ)
- Настройка QoS (prefetch)

### Требования

| Зависимость | Версия |
|---|---|
| Apache Airflow | `>=2.7.0, <3.0.0` |
| pika | `>=1.3.0, <2.0.0` |
| aio-pika | `>=9.0.0, <10.0.0` |
| tenacity | `>=8.0.0` |
| Python | `>=3.10` |

---

## Установка

### Установка из PyPI

```bash
pip install apache-airflow-provider-rmq
```

### Сборка из исходников

```bash
git clone https://github.com/mkozhin/apache-airflow-provider-rmq.git
cd apache-airflow-provider-rmq
pip install build
python -m build
pip install dist/apache_airflow_provider_rmq-*.whl
```

---

## Настройка подключения

Создайте новое подключение в интерфейсе Airflow (**Admin > Connections**):

| Поле | Значение | Описание |
|---|---|---|
| Connection Id | `rmq_default` | Любой уникальный ID |
| Connection Type | `AMQP` | Зарегистрирован провайдером |
| Host | `localhost` | Хост сервера RabbitMQ |
| Port | `5672` | `5671` для SSL |
| Login | `guest` | Имя пользователя RabbitMQ |
| Password | `guest` | Пароль RabbitMQ |
| Schema | `/` | Виртуальный хост (vhost) |

### Настройка SSL/TLS

Добавьте SSL-настройки в поле **Extra** в формате JSON:

```json
{
  "ssl_enabled": true,
  "ca_certs": "/path/to/ca.pem",
  "certfile": "/path/to/client-cert.pem",
  "keyfile": "/path/to/client-key.pem",
  "cert_reqs": "CERT_REQUIRED"
}
```

Хук также предоставляет пользовательские виджеты для SSL-полей (`ssl_enabled`, `ca_certs`, `certfile`, `keyfile`), видимые в форме подключения Airflow.

Установите `"cert_reqs": "CERT_NONE"` для отключения проверки сертификатов (не рекомендуется для продакшена).

---

## Компоненты

### RMQHook

**Импорт:** `from apache_airflow_provider_rmq.hooks.rmq import RMQHook`

Основной хук для всех взаимодействий с RabbitMQ. Использует pika `BlockingConnection` с автоматической логикой повторных попыток (tenacity). Соединение закрывается автоматически, когда объект хука уничтожается сборщиком мусора, поэтому вызывать `close()` вручную не нужно. Контекстный менеджер (`with`) также поддерживается.

#### Параметры конструктора

| Параметр | Тип | По умолчанию | Обязательный | Описание |
|---|---|---|---|---|
| `rmq_conn_id` | `str` | `"rmq_default"` | Нет | ID подключения Airflow |
| `vhost` | `str \| None` | `None` | Нет | Переопределить виртуальный хост из подключения |
| `qos` | `dict \| None` | `None` | Нет | Настройки QoS: `prefetch_size`, `prefetch_count`, `global_qos` |
| `retry_count` | `int` | `3` | Нет | Количество попыток переподключения |
| `retry_delay` | `float` | `1.0` | Нет | Базовая задержка (секунды) между попытками (экспоненциальный рост) |

#### Основные методы

| Метод | Описание |
|---|---|
| `get_channel()` | Возвращает pika `BlockingChannel` (создаёт подключение лениво) |
| `queue_declare(queue_name, passive, durable, exclusive, auto_delete, arguments)` | Объявить очередь |
| `queue_delete(queue_name, if_unused, if_empty)` | Удалить очередь |
| `queue_bind(queue, exchange, routing_key, arguments)` | Привязать очередь к обменнику |
| `queue_unbind(queue, exchange, routing_key, arguments)` | Отвязать очередь от обменника |
| `queue_purge(queue_name)` | Удалить все сообщения из очереди |
| `queue_info(queue_name)` | Получить информацию об очереди (message_count, consumer_count, exists) |
| `exchange_declare(exchange, exchange_type, passive, durable, auto_delete, internal, arguments)` | Объявить обменник |
| `exchange_delete(exchange, if_unused)` | Удалить обменник |
| `exchange_bind(destination, source, routing_key, arguments)` | Привязать обменник к обменнику |
| `exchange_unbind(destination, source, routing_key, arguments)` | Отвязать обменник от обменника |
| `basic_publish(exchange, routing_key, body, properties)` | Опубликовать сообщение |
| `consume_messages(queue_name, max_messages, auto_ack, inactivity_timeout)` | Потребить сообщения из очереди |
| `ack(delivery_tag)` | Подтвердить сообщение |
| `nack(delivery_tag, requeue)` | Отклонить сообщение |
| `build_dlq_arguments(dlx_exchange, dlx_routing_key, message_ttl)` | Статический метод: собрать `x-*` аргументы для поддержки DLQ |
| `test_connection()` | Проверить подключение (используется UI Airflow) |
| `close()` | Закрыть канал и подключение |

#### Пример использования

```python
from apache_airflow_provider_rmq.hooks.rmq import RMQHook

hook = RMQHook(rmq_conn_id="rmq_default")
info = hook.queue_info("my_queue")
print(f"Сообщений в очереди: {info['message_count']}")

hook.basic_publish(
    exchange="",
    routing_key="my_queue",
    body='{"key": "value"}',
)
# Соединение закроется автоматически при выходе hook из области видимости
```

---

### RMQPublishOperator

**Импорт:** `from apache_airflow_provider_rmq.operators.rmq_publish import RMQPublishOperator`

Публикует одно или несколько сообщений в RabbitMQ. Поддерживает строки, словари (автоматическая сериализация в JSON) и списки.

#### Параметры

| Параметр | Тип | По умолчанию | Обязательный | Описание |
|---|---|---|---|---|
| `rmq_conn_id` | `str` | `"rmq_default"` | Нет | ID подключения Airflow |
| `exchange` | `str` | `""` | Нет | Обменник для публикации (пустая строка = обменник по умолчанию) |
| `routing_key` | `str` | `""` | Нет | Ключ маршрутизации сообщения |
| `message` | `str \| list[str] \| dict \| list[dict] \| None` | `None` | Нет | Тело сообщения. Словари сериализуются в JSON |
| `queue_name` | `str \| None` | `None` | Нет | Ярлык: устанавливает `exchange=""` и `routing_key=queue_name` |
| `content_type` | `str \| None` | `None` | Нет | AMQP заголовок content type (например, `"application/json"`) |
| `delivery_mode` | `int \| None` | `None` | Нет | `1` = непостоянное, `2` = постоянное (persistent) |
| `headers` | `dict \| None` | `None` | Нет | Пользовательские AMQP заголовки |
| `priority` | `int \| None` | `None` | Нет | Приоритет сообщения (0-9) |
| `expiration` | `str \| None` | `None` | Нет | TTL сообщения в миллисекундах (строка, например `"60000"`) |
| `correlation_id` | `str \| None` | `None` | Нет | Идентификатор корреляции |
| `reply_to` | `str \| None` | `None` | Нет | Имя очереди для ответа |
| `message_id` | `str \| None` | `None` | Нет | Идентификатор сообщения |

**Шаблонные поля:** `exchange`, `routing_key`, `message`

#### Пример использования

```python
# Публикация словаря в очередь
RMQPublishOperator(
    task_id="publish",
    queue_name="my_queue",
    message={"event": "order_created", "id": 42},
    delivery_mode=2,
    headers={"x-source": "airflow"},
)

# Публикация пакета сообщений в обменник
RMQPublishOperator(
    task_id="publish_batch",
    exchange="events",
    routing_key="orders.new",
    message=[
        {"id": 1, "item": "widget"},
        {"id": 2, "item": "gadget"},
    ],
)
```

---

### RMQConsumeOperator

**Импорт:** `from apache_airflow_provider_rmq.operators.rmq_consume import RMQConsumeOperator`

Потребляет сообщения из очереди RabbitMQ. Подходящие сообщения подтверждаются (ACK) и возвращаются через XCom. Неподходящие отклоняются (NACK) с `requeue=True`.

#### Параметры

| Параметр | Тип | По умолчанию | Обязательный | Описание |
|---|---|---|---|---|
| `queue_name` | `str` | — | **Да** | Имя очереди для потребления |
| `rmq_conn_id` | `str` | `"rmq_default"` | Нет | ID подключения Airflow |
| `max_messages` | `int` | `100` | Нет | Максимальное количество сообщений за выполнение |
| `filter_headers` | `dict[str, Any] \| None` | `None` | Нет | Словарь AMQP заголовков для фильтрации. Поддерживает ключи `body.*` для фильтрации по JSON-телу (например, `{"body.data.status": "active"}`) |
| `filter_callable` | `Callable[[Any, str], bool] \| None` | `None` | Нет | Пользовательская функция фильтрации `(properties, body_str) -> bool` |
| `qos` | `dict \| None` | `None` | Нет | Настройки QoS: `{"prefetch_count": 10}` |

**Шаблонные поля:** `queue_name`

**Возвращает:** `list[dict]` — список подошедших сообщений, каждое с ключами: `body`, `headers`, `routing_key`, `exchange`

#### Пример использования

```python
# Потребление с фильтром по заголовкам
RMQConsumeOperator(
    task_id="consume_orders",
    queue_name="orders",
    filter_headers={"x-type": "order"},
    max_messages=50,
    qos={"prefetch_count": 10},
)

# Потребление с фильтром по телу сообщения
RMQConsumeOperator(
    task_id="consume_active",
    queue_name="events",
    filter_headers={"body.status": "active"},
)

# Потребление с пользовательской функцией фильтрации
def large_orders(properties, body: str) -> bool:
    import json
    data = json.loads(body)
    return data.get("amount", 0) > 1000

RMQConsumeOperator(
    task_id="consume_large",
    queue_name="orders",
    filter_callable=large_orders,
)
```

#### Обработка сообщений через TaskFlow API

`RMQConsumeOperator` возвращает `list[dict]` через XCom. Используйте `consume.output` в `@task`-функции для доступа к каждому сообщению:

```python
from airflow.decorators import dag, task
from apache_airflow_provider_rmq.operators.rmq_consume import RMQConsumeOperator

@dag(...)
def my_pipeline():
    consume = RMQConsumeOperator(
        task_id="consume",
        queue_name="orders",
        max_messages=50,
    )

    @task
    def process_messages(messages: list[dict]) -> list[dict]:
        results = []
        for msg in messages:
            body = msg["body"]          # тело сообщения (str)
            headers = msg["headers"]    # AMQP заголовки (dict)
            rk = msg["routing_key"]     # ключ маршрутизации
            exchange = msg["exchange"]  # обменник-источник
            log.info("Сообщение: body=%s, headers=%s", body, headers)

            data = json.loads(body)
            results.append(data)
        return results

    processed = process_messages(consume.output)
    processed >> next_task  # передать результаты дальше
```

---

### RMQQueueManagementOperator

**Импорт:** `from apache_airflow_provider_rmq.operators.rmq_management import RMQQueueManagementOperator`

Выполняет операции управления очередями и обменниками в RabbitMQ.

#### Параметры

| Параметр | Тип | По умолчанию | Обязательный | Описание |
|---|---|---|---|---|
| `action` | `str` | — | **Да** | Действие (см. таблицу ниже) |
| `rmq_conn_id` | `str` | `"rmq_default"` | Нет | ID подключения Airflow |
| `queue_name` | `str \| None` | `None` | Условно | Имя очереди (обязательно для операций с очередями) |
| `durable` | `bool` | `False` | Нет | Ресурс переживает перезапуск брокера |
| `exclusive` | `bool` | `False` | Нет | Очередь эксклюзивна для этого подключения |
| `auto_delete` | `bool` | `False` | Нет | Ресурс удаляется, когда больше не используется |
| `exchange_name` | `str \| None` | `None` | Условно | Имя обменника (обязательно для операций с обменниками) |
| `exchange_type` | `str` | `"direct"` | Нет | Тип обменника: `direct`, `fanout`, `topic`, `headers` |
| `internal` | `bool` | `False` | Нет | Обменник не может принимать сообщения напрямую |
| `if_unused` | `bool` | `False` | Нет | Удалять только если нет потребителей/привязок |
| `if_empty` | `bool` | `False` | Нет | Удалять очередь только если она пуста |
| `routing_key` | `str` | `""` | Нет | Ключ маршрутизации для bind/unbind |
| `arguments` | `dict \| None` | `None` | Нет | Дополнительные `x-*` аргументы (например, настройки DLQ) |
| `source_exchange` | `str \| None` | `None` | Условно | Обменник-источник для exchange bind/unbind |

**Шаблонные поля:** `queue_name`, `exchange_name`, `routing_key`

#### Поддерживаемые действия

| Действие | Обязательные параметры | Описание |
|---|---|---|
| `declare_queue` | `queue_name` | Создать очередь |
| `delete_queue` | `queue_name` | Удалить очередь |
| `purge_queue` | `queue_name` | Удалить все сообщения из очереди |
| `bind_queue` | `queue_name`, `exchange_name` | Привязать очередь к обменнику |
| `unbind_queue` | `queue_name`, `exchange_name` | Отвязать очередь от обменника |
| `declare_exchange` | `exchange_name` | Создать обменник |
| `delete_exchange` | `exchange_name` | Удалить обменник |
| `bind_exchange` | `exchange_name`, `source_exchange` | Привязать обменник к обменнику |
| `unbind_exchange` | `exchange_name`, `source_exchange` | Отвязать обменник от обменника |

#### Пример использования

```python
# Создать durable очередь
RMQQueueManagementOperator(
    task_id="create_queue",
    action="declare_queue",
    queue_name="my_queue",
    durable=True,
)

# Создать topic обменник и привязать очередь
RMQQueueManagementOperator(
    task_id="create_exchange",
    action="declare_exchange",
    exchange_name="events",
    exchange_type="topic",
    durable=True,
)

RMQQueueManagementOperator(
    task_id="bind",
    action="bind_queue",
    queue_name="my_queue",
    exchange_name="events",
    routing_key="orders.*",
)
```

---

### RMQSensor

**Импорт:** `from apache_airflow_provider_rmq.sensors.rmq import RMQSensor`

Ожидает сообщение в очереди RabbitMQ, соответствующее условиям фильтрации. Поддерживает классический poke-режим и отложенный (deferrable) режим.

#### Параметры

| Параметр | Тип | По умолчанию | Обязательный | Описание |
|---|---|---|---|---|
| `queue_name` | `str` | — | **Да** | Имя очереди для мониторинга |
| `rmq_conn_id` | `str` | `"rmq_default"` | Нет | ID подключения Airflow |
| `filter_headers` | `dict[str, Any] \| None` | `None` | Нет | Фильтр по заголовкам/телу (словарь) |
| `filter_callable` | `Callable \| None` | `None` | Нет | Пользовательская функция фильтрации. **Не поддерживается с `deferrable=True`** |
| `deferrable` | `bool` | `False` | Нет | Использовать отложенный режим (освобождает слот воркера) |
| `poke_batch_size` | `int` | `100` | Нет | Максимум сообщений за один цикл проверки |
| `poke_interval` | `float` | `60` | Нет | Секунды между проверками (наследуется от BaseSensorOperator) |
| `timeout` | `float` | `604800` | Нет | Максимум секунд ожидания до ошибки (наследуется от BaseSensorOperator) |
| `mode` | `str` | `"poke"` | Нет | `"poke"` или `"reschedule"` (наследуется от BaseSensorOperator) |

**Шаблонные поля:** `queue_name`

**Возвращает:** `dict | None` — подошедшее сообщение с ключами: `body`, `headers`, `routing_key`, `exchange`

#### Отложенный (deferrable) режим

При `deferrable=True` сенсор передаёт выполнение в процесс triggerer через `RMQTrigger`. Это освобождает слот воркера на время ожидания, что более эффективно при длительном ожидании.

**Ограничение:** `filter_callable` нельзя использовать с `deferrable=True`, так как Python-функции не могут быть сериализованы для передачи в triggerer. Используйте `filter_headers` вместо этого.

#### Пример использования

```python
# Классический poke-режим с пользовательским фильтром
RMQSensor(
    task_id="wait_for_order",
    queue_name="orders",
    filter_callable=lambda props, body: "urgent" in body,
    poke_interval=10,
    timeout=300,
    mode="reschedule",
)

# Отложенный режим с фильтром по заголовкам
RMQSensor(
    task_id="wait_for_event",
    queue_name="events",
    filter_headers={"x-type": "payment"},
    deferrable=True,
    timeout=600,
)
```

#### Обработка результата сенсора через TaskFlow API

`RMQSensor` возвращает `dict | None` через XCom. Используйте `sensor.output` в `@task`-функции для доступа к найденному сообщению:

```python
from airflow.decorators import dag, task
from apache_airflow_provider_rmq.sensors.rmq import RMQSensor

@dag(...)
def my_pipeline():
    wait = RMQSensor(
        task_id="wait_for_event",
        queue_name="events",
        filter_headers={"x-type": "payment"},
        deferrable=True,
    )

    @task
    def handle_event(message: dict):
        log.info("Получено: %s", message)
        return message

    handle_event(wait.output)
```

---

### RMQTrigger

**Импорт:** `from apache_airflow_provider_rmq.triggers.rmq import RMQTrigger`

Асинхронный триггер для отложенного режима сенсора. Использует `aio_pika` для неблокирующего AMQP-доступа. Обычно не используется напрямую — `RMQSensor` с `deferrable=True` создаёт его автоматически.

#### Параметры

| Параметр | Тип | По умолчанию | Обязательный | Описание |
|---|---|---|---|---|
| `rmq_conn_id` | `str` | — | **Да** | ID подключения Airflow |
| `queue_name` | `str` | — | **Да** | Очередь для опроса |
| `filter_data` | `dict \| None` | `None` | Нет | Сериализованный фильтр из `MessageFilter.serialize()` |
| `poll_interval` | `float` | `5.0` | Нет | Секунды между опросами при пустой очереди |

---

### MessageFilter (утилита)

**Импорт:** `from apache_airflow_provider_rmq.utils.filters import MessageFilter`

Проверяет, соответствует ли сообщение RabbitMQ заданным условиям фильтрации. Используется внутри операторами и сенсорами.

#### Режимы фильтрации

1. **Фильтрация по заголовкам** (`filter_headers`): словарь пар ключ-значение, которым должны соответствовать заголовки сообщения.
   - Обычные ключи проверяют словарь `properties.headers`
   - Ключи, начинающиеся с `body.`, обходят JSON-тело сообщения (например, `{"body.data.status": "active"}`)

2. **Фильтрация функцией** (`filter_callable`): `fn(properties, body_str) -> bool`

Оба режима можно комбинировать (логика И: оба условия должны выполниться).

---

## Примеры DAG

Пакет включает несколько примеров DAG в `apache_airflow_provider_rmq/example_dags/`. Все примеры используют **TaskFlow API** (декораторы `@dag` / `@task`) и демонстрируют **обработку полученных сообщений** в downstream-тасках через XCom.

| DAG | Описание |
|---|---|
| `rmq_example_basic` | Публикация, ожидание, потребление, обработка сообщений, очистка |
| `rmq_publish_advanced` | Продвинутая публикация со всеми AMQP-свойствами, пакетная отправка, topic exchange |
| `rmq_consume_with_filters` | Фильтры по заголовкам, по телу, пользовательские функции, QoS — с пошаговой обработкой сообщений |
| `rmq_sensor_deferrable` | Отложенный сенсор с фильтрацией по заголовкам и обработкой сообщений |
| `rmq_pipeline_start` / `rmq_pipeline_finish` | Паттерн блокировки пайплайна — предотвращение параллельных запусков |
| `rmq_dlq_setup` | Настройка инфраструктуры Dead Letter Queue с DLX, TTL, exchange-to-exchange привязками |

---

## Структура репозитория

```
apache-airflow-provider-rmq/
├── apache_airflow_provider_rmq/
│   ├── __init__.py                  # Метаданные провайдера и get_provider_info()
│   ├── hooks/
│   │   └── rmq.py                   # RMQHook
│   ├── operators/
│   │   ├── rmq_publish.py           # RMQPublishOperator
│   │   ├── rmq_consume.py           # RMQConsumeOperator
│   │   └── rmq_management.py        # RMQQueueManagementOperator
│   ├── sensors/
│   │   └── rmq.py                   # RMQSensor
│   ├── triggers/
│   │   └── rmq.py                   # RMQTrigger
│   ├── utils/
│   │   ├── filters.py               # MessageFilter
│   │   └── ssl.py                   # build_ssl_context()
│   └── example_dags/                # Примеры DAG
├── tests/                           # Модульные тесты
├── pyproject.toml
└── readme.md
```

---

## Запуск тестов

```bash
# Установка dev-зависимостей
pip install -e ".[dev]"

# Запуск всех тестов
pytest tests/

# Запуск конкретного модуля тестов
pytest tests/test_trigger.py -v
```

---

## Лицензия

Apache License 2.0. См. [LICENSE](LICENSE) для подробностей.
